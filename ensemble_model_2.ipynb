{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SF Crime Analysis: Ensemble Model\n",
    "\n",
    "### Data-x (IEOR 135)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "df1 = pd.read_csv('Police_Department_Incident_Reports__Historical_2003_to_May_2018.csv')\n",
    "#df2 = pd.read_csv('311_Cases.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format date columns\n",
    "df1['Date'] = pd.to_datetime(df1['Date'])\n",
    "df1['Year-Month'] = df1['Date'].map(lambda x: '{year}-{month}'.format(year=x.year,\n",
    "                                                              month=x.month,\n",
    "                                                            day=x.day))\n",
    "df1['Year'] = df1['Date'].dt.year.astype(int)\n",
    "df1['Week_Number'] = df1['Date'].dt.week\n",
    "df1['Month_Number'] = df1['Date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splice relevant columns\n",
    "dfDecompose = df1[['IncidntNum','Category','Year','Week_Number', \"Month_Number\", 'Date']]\n",
    "\n",
    "# Select ASSAULT crimes only\n",
    "dfDecompose = dfDecompose[dfDecompose['Category'] == 'ASSAULT']\n",
    "\n",
    "# Drop records from 2018 since data from only part of the year is available\n",
    "dfDecompose = dfDecompose[(dfDecompose['Year'] < 2018)]\n",
    "\n",
    "# Group by month\n",
    "monthGrouped = dfDecompose.resample('M', on='Date')[['IncidntNum']].count() #.reset_index().sort_values(by='Date')\n",
    "monthGrouped.rename(columns = {'IncidntNum': \"Incidents/Month\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Metrics to Compare Models\n",
    "\n",
    "The models will be compared with the following metrics. Models are tested on data from 2003  - 2016 and then tested on 2017 data.\n",
    "\n",
    "**Mean Absolute Error (MAE)** <br>\n",
    "$Error =  mean( |y_{actual} - y_{predict}|)$\n",
    "\n",
    "**Root Mean Squared Error** <br>\n",
    "$Error =  \\sqrt{mean((y_{actual} - y_{predict})^{2})}$\n",
    "\n",
    "**Mean Abosolute Percentage Error (MAPE)** <br>\n",
    "$Error =  mean(|\\frac{y_{actual} - y_{predict}}{y_{actual}}|)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions to quantify forecast error\n",
    "# Referenced from https://otexts.com/fpp2/accuracy.html\n",
    "\n",
    "# Mean Absolute Error\n",
    "def mae(y_predict, y_actual):\n",
    "    return round(np.mean(abs(y_predict - y_actual)),2)\n",
    "\n",
    "# Mean Root Squared Error\n",
    "def rmse(y_predict, y_actual):\n",
    "    return round(np.sqrt(np.mean((y_predict - y_actual)**2)),2)\n",
    "\n",
    "# Mean Absolute Percentage Error\n",
    "def MAPE(y_predict, y_actual):\n",
    "    return round(np.mean(abs((y_predict - y_actual)/y_actual)) * 100,2)\n",
    "\n",
    "def print_error(predictedValues, actualValues):\n",
    "    print(\"OUT OF SAMPLE ERROR:\") \n",
    "    print(\"Mean Absolute Error (MSE): \", mae(predictedValues, actualValues))\n",
    "    print(\"Root Mean Squared Error (RSME): \", rmse(predictedValues, actualValues))\n",
    "    print(\"Mean Absolute Percentage Error (MAPE): \", MAPE(predictedValues, actualValues), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Incidents/Month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003-01-31</th>\n",
       "      <td>1174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-02-28</th>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-03-31</th>\n",
       "      <td>1231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-04-30</th>\n",
       "      <td>1016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-05-31</th>\n",
       "      <td>1117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-31</th>\n",
       "      <td>1293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-30</th>\n",
       "      <td>1188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-31</th>\n",
       "      <td>1183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-30</th>\n",
       "      <td>1089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31</th>\n",
       "      <td>1082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Incidents/Month\n",
       "Date                       \n",
       "2003-01-31             1174\n",
       "2003-02-28             1050\n",
       "2003-03-31             1231\n",
       "2003-04-30             1016\n",
       "2003-05-31             1117\n",
       "...                     ...\n",
       "2017-08-31             1293\n",
       "2017-09-30             1188\n",
       "2017-10-31             1183\n",
       "2017-11-30             1089\n",
       "2017-12-31             1082\n",
       "\n",
       "[180 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data we are using to forecast\n",
    "monthGrouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = monthGrouped[monthGrouped.index.year < 2017]\n",
    "test = monthGrouped[monthGrouped.index.year == 2017]['Incidents/Month']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SARIMA Model\n",
    "\n",
    "Analysis steps and code from https://www.machinelearningplus.com/time-series/arima-model-time-series-forecasting-python/\n",
    "\n",
    "Seasonal Auto Regressive Integrated Moving Average (ARIMA) models are linear regression models built upon lags (different between current and previous obsevation) and forecast errors.\n",
    "\n",
    "ARIMA model parameters:\n",
    "- p is the order of the AR term (the number of lags to be used as predictors)\n",
    "- q is the order of the MA term (then number of lagged forecast errors to be used as predictors)\n",
    "- d is the number of differencing required to make the time series stationary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code adapted from https://github.com/liyenhsu/SF-Crime-Analysis/blob/master/sf_crime_analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import warnings\n",
    "import itertools\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarima_model(train, steps):\n",
    "    p = d = q = range(0, 2)\n",
    "    pdq = list(itertools.product(p, d, q))\n",
    "    seasonal_pdq = [(x[0], x[1], x[2], 12) for x in pdq]\n",
    "    aic_min = float(\"inf\")\n",
    "    param = (0,0,0,0,0,0)\n",
    "    best_model = None\n",
    "\n",
    "    for x1 in pdq:\n",
    "        for x2 in seasonal_pdq:\n",
    "            try:\n",
    "                mod = SARIMAX(train,\n",
    "                              order = x1,\n",
    "                              seasonal_order = x2,\n",
    "                              enforce_stationarity = False,\n",
    "                              enforce_invertibility = False)\n",
    "                results = mod.fit()\n",
    "                if results.aic < aic_min:\n",
    "                    aic_min = results.aic\n",
    "                    param = x1 + x2\n",
    "                    best_model = mod\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "    results = best_model.fit()\n",
    "    pred_test = results.get_forecast(steps=steps).predicted_mean\n",
    "    return pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2017-01-31    1169.037887\n",
       "2017-02-28    1100.222483\n",
       "2017-03-31    1216.335264\n",
       "2017-04-30    1168.424798\n",
       "2017-05-31    1206.697756\n",
       "2017-06-30    1155.422937\n",
       "2017-07-31    1162.419823\n",
       "2017-08-31    1184.491681\n",
       "2017-09-30    1230.416168\n",
       "2017-10-31    1248.051253\n",
       "2017-11-30    1129.638917\n",
       "2017-12-31    1090.291356\n",
       "Freq: M, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sarima_model(train, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triple Exponential Smoothing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "\n",
    "def triple_exp_smoothing_model(train, steps):\n",
    "    # create class\n",
    "    model = ExponentialSmoothing(train, \n",
    "                                 trend = 'add', \n",
    "                                 seasonal = 'add',\n",
    "                                 seasonal_periods = 12)\n",
    "\n",
    "    # fit model\n",
    "    model_fit = model.fit()\n",
    "\n",
    "    # make prediction\n",
    "    pred_test = model_fit.forecast(steps)\n",
    "    \n",
    "    return pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2017-01-31    1180.389778\n",
       "2017-02-28    1107.398498\n",
       "2017-03-31    1223.549672\n",
       "2017-04-30    1175.853951\n",
       "2017-05-31    1213.915094\n",
       "2017-06-30    1162.580077\n",
       "2017-07-31    1169.480749\n",
       "2017-08-31    1191.590967\n",
       "2017-09-30    1237.489955\n",
       "2017-10-31    1255.187728\n",
       "2017-11-30    1136.700618\n",
       "2017-12-31    1097.402991\n",
       "Freq: M, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triple_exp_smoothing_model(train, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis ideas from http://mariofilho.com/how-to-predict-multiple-time-series-with-scikit-learn-with-sales-forecasting-example/\n",
    "\n",
    "Builds Random Forest model off of lags (current month minus previous month) and number of crimes in the previous month. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn.model_selection\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lag_prevObsers(X_rf):\n",
    "    \"\"\" Creates a copy of the input dataframe and adds columns for previous crime count and lags\n",
    "    \"\"\" \n",
    "    X = X_rf.copy()\n",
    "    \n",
    "    # Add featurs which says the current month that is being predicted\n",
    "    X['MonthNum'] =  X_rf.index.month\n",
    "    \n",
    "    # Add number of crimes observed in the previous month\n",
    "    X['Last_Month_Count'] =  X['Incidents/Month'].shift(1)\n",
    "    X['Last-1_Month_Count'] =  X['Incidents/Month'].shift(2)\n",
    "    X['Last-2_Month_Count'] =  X['Incidents/Month'].shift(3)\n",
    "    #X['Last-11_Month_Count'] =  X['Incidents/Month'].shift(12)\n",
    "    \n",
    "    # Add lag columns\n",
    "    for i,col in enumerate(['Last-1_Month_Count','Last-2_Month_Count']):\n",
    "        X['Lag_' + str(i+1) + \"_Month\"] = X['Last_Month_Count'] - X[col]\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out of Sample Testing\n",
    "\n",
    "Calculating the OOS error is a bit difficult because to forecast one month requires the number of crime in the months before it. We can forecast one month into the future, however, if we want to forecast 2 months into the future we will need to use the forecast for the first month as an input into the 2nd months forecast.\n",
    "\n",
    "We have used this process to forecast 12 months out. Because previous forecasts are used to calculate the next moth, the error builds with each consecutive forecast.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to forecast, a month I will need the number of crimes observed in previous months and \n",
    "# the lag between the last month and other previous months. These functions input a DataFrame called\n",
    "# y_last that has the date as the index and the return then number of lags or observations i months ago\n",
    "\n",
    "def get_Last_Minus_i_Month_Count(y_past, i):\n",
    "    return int(y_past.iloc[-(i+1),:])\n",
    "\n",
    "def get_Lag_i_Month_Count(y_past, i):\n",
    "    return get_Last_Minus_i_Month_Count(y_past, 0) - get_Last_Minus_i_Month_Count(y_past, i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModelInputRow(y_input, date):\n",
    "    \"\"\" In order to forecast, we need the lags and number of crimes observed in previous months. This function inputs a DataFrame\n",
    "        of with index as the dates and a column with the observations and returns a row vector with each entry corresponding to \n",
    "        the previous months number of observations and lags.\n",
    "    \"\"\"\n",
    "    # Initialize row vector that will be returned\n",
    "    x_test = []\n",
    "    \n",
    "    # Add month\n",
    "    x_test.append(date.month)\n",
    "    \n",
    "    # Add previous month entries\n",
    "    for i in [0,1,2]:\n",
    "        x_test.append(get_Last_Minus_i_Month_Count(y_input, i))\n",
    "    \n",
    "    # Add lag entries\n",
    "    for i in [1,2]:\n",
    "        x_test.append(get_Lag_i_Month_Count(y_input, i))\n",
    "        \n",
    "    return [x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_split_for_machine_learning(train):\n",
    "    # Add lags and umber of crimes in past months to a copy of months Grouped\n",
    "    X_rfFeatures = add_lag_prevObsers(train)\n",
    "\n",
    "    # Clean data before training model\n",
    "    X_rfFeatures.dropna(inplace = True)\n",
    "\n",
    "    #Split into X and Y training data\n",
    "    X_train = X_rfFeatures.drop(columns = ['Incidents/Month'])\n",
    "    y_train = X_rfFeatures['Incidents/Month']\n",
    "    \n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_training(random_forest_model, train, y_train, steps):\n",
    "    \n",
    "    # Create a copy of the number of observed crimes to append to later.\n",
    "    y_hist = pd.DataFrame(y_train)\n",
    "\n",
    "    # Get month indexes in 2017 to predict on\n",
    "    months_indexes_to_forecast = triple_exp_smoothing_model(train, steps).index\n",
    "\n",
    "    # Initialize an empty DataFrame where forecasts will be placed in\n",
    "    rfForecast_df = pd.DataFrame()\n",
    "\n",
    "    # Loop through the date indexes and forecast each date. Add that date to the dataframe and use that forecasted quantity to\n",
    "    # predict the demand for the next month until the whole year has forecasts\n",
    "    for date in months_indexes_to_forecast:\n",
    "        nextRow = getModelInputRow(y_hist, date)\n",
    "        y_pred = random_forest_model.predict(nextRow)\n",
    "        forecastRow = pd.DataFrame(data = [y_pred], columns = ['Incidents/Month'], index = [date])\n",
    "        y_hist = y_hist.append(forecastRow)\n",
    "        rfForecast_df = rfForecast_df.append(forecastRow)\n",
    "        \n",
    "    # Make forecasts into a series so it ca nbe graphed\n",
    "    test_pred = rfForecast_df['Incidents/Month']\n",
    "    \n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_model(train, steps):\n",
    "    \n",
    "    X_train, y_train = prepare_split_for_machine_learning(train)\n",
    "    \n",
    "    # Initialize and create Random Forest Model\n",
    "    RF = RandomForestRegressor()\n",
    "    RF.fit(X_train, y_train)\n",
    "    \n",
    "    # Iteratively create forecasts. Testing the forecast into the future is difficult because each forecast depends on the \n",
    "    # number of crimes in the previous month. When forecasting 2 steps into the future, the forecast for the previous month is used\n",
    "    # in the forecast for the following month. \n",
    "    \n",
    "    test_pred = predict_on_training(RF, train, y_train, steps)\n",
    "\n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2017-01-31    1095.5\n",
       "2017-02-28    1105.9\n",
       "2017-03-31    1148.8\n",
       "2017-04-30    1127.5\n",
       "2017-05-31    1122.6\n",
       "2017-06-30    1065.6\n",
       "2017-07-31    1063.0\n",
       "2017-08-31    1065.3\n",
       "2017-09-30    1103.2\n",
       "2017-10-31    1138.4\n",
       "2017-11-30    1012.4\n",
       "2017-12-31     960.3\n",
       "Name: Incidents/Month, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_model(train, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaboost_model(train, steps):\n",
    "    \n",
    "    X_train, y_train = prepare_split_for_machine_learning(train)\n",
    "    \n",
    "    # Initialize and Adaboost Regressor Model\n",
    "    adaboostRegr = RandomForestRegressor()\n",
    "\n",
    "    # Train on X_train and y_train created in the Random Forest section\n",
    "    adaboostRegr.fit(X_train, y_train)\n",
    "    \n",
    "    # Iteratively create forecasts. Testing the forecast into the future is difficult because each forecast depends on the \n",
    "    # number of crimes in the previous month. When forecasting 2 steps into the future, the forecast for the previous month is used\n",
    "    # in the forecast for the following month. \n",
    "    \n",
    "    test_pred = predict_on_training(adaboostRegr, train, y_train, steps)\n",
    "\n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2017-01-31    1084.4\n",
       "2017-02-28    1102.5\n",
       "2017-03-31    1093.3\n",
       "2017-04-30    1143.7\n",
       "2017-05-31    1126.7\n",
       "2017-06-30    1082.1\n",
       "2017-07-31    1107.7\n",
       "2017-08-31    1078.9\n",
       "2017-09-30    1130.3\n",
       "2017-10-31    1143.0\n",
       "2017-11-30    1055.6\n",
       "2017-12-31     958.7\n",
       "Name: Incidents/Month, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost_model(train, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "def gradient_boosting_model(train, steps):\n",
    "    \n",
    "    X_train, y_train = prepare_split_for_machine_learning(train)\n",
    "    \n",
    "    # Initialize and Adaboost Regressor Model\n",
    "    gradBoostRegr = GradientBoostingRegressor()\n",
    "\n",
    "    # Train on X_train and y_train created in the Random Forest section\n",
    "    gradBoostRegr.fit(X_train, y_train)\n",
    "    \n",
    "    # Iteratively create forecasts. Testing the forecast into the future is difficult because each forecast depends on the \n",
    "    # number of crimes in the previous month. When forecasting 2 steps into the future, the forecast for the previous month is used\n",
    "    # in the forecast for the following month. \n",
    "    \n",
    "    test_pred = predict_on_training(gradBoostRegr, train, y_train, steps)\n",
    "\n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2017-01-31    1072.554512\n",
       "2017-02-28    1096.297944\n",
       "2017-03-31    1073.290873\n",
       "2017-04-30    1139.654215\n",
       "2017-05-31    1105.838000\n",
       "2017-06-30    1112.457225\n",
       "2017-07-31    1089.977325\n",
       "2017-08-31    1098.314328\n",
       "2017-09-30    1113.004223\n",
       "2017-10-31    1138.229903\n",
       "2017-11-30    1053.601658\n",
       "2017-12-31     964.742448\n",
       "Name: Incidents/Month, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_boosting_model(train, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predict(train, steps):\n",
    "    # Run models for 12 time steps into the future\n",
    "    \n",
    "    print(\"|--\", end='')\n",
    "    rf = random_forest_model(train, 12)\n",
    "    print(\"-----\", end='')\n",
    "    \n",
    "    adabst = adaboost_model(train, 12)\n",
    "    print(\"-------\", end='')\n",
    "    \n",
    "    gradbst = gradient_boosting_model(train, 12)\n",
    "    print(\"---------\", end='')\n",
    "    \n",
    "    #sarima = sarima_model(train, 12)\n",
    "    #print(\"SARIMA model trained!\")\n",
    "    \n",
    "    exp_sm = triple_exp_smoothing_model(train, 12)\n",
    "    print(\"-----------\", end=\"\")\n",
    "    \n",
    "    # Combine models into a dataframe\n",
    "    combined_fcst = pd.concat([rf, adabst, gradbst, exp_sm], axis=1)\n",
    "    combined_fcst.columns = ['rn_frst', 'adabst', 'gradbst', 'exp_sm']\n",
    "    \n",
    "    # Take the average forecast across all models as the estimate forecast\n",
    "    combined_fcst['avg_fcst'] = combined_fcst.mean(axis = 1)\n",
    "    return combined_fcst.avg_fcst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|----------------------------------"
     ]
    }
   ],
   "source": [
    "forecast = ensemble_predict(train, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
